{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.21.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.21.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.2 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.21.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.21.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.21.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import shelve\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline \n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from inspector.app.utils import get_feature_values\n",
    "from inspector.app.utils.model import Model\n",
    "from inspector.app.views import gather_values\n",
    "\n",
    "import re\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "SEED = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>av_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>num_acl</th>\n",
       "      <th>num_rel_cl</th>\n",
       "      <th>num_advcl</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>num_tok</th>\n",
       "      <th>av_tok_before_root</th>\n",
       "      <th>av_len_sent</th>\n",
       "      <th>...</th>\n",
       "      <th>num_linkings</th>\n",
       "      <th>num_4grams</th>\n",
       "      <th>num_func_ngrams</th>\n",
       "      <th>num_shell_noun</th>\n",
       "      <th>num_misspelled_tokens</th>\n",
       "      <th>million_mistake</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>type</th>\n",
       "      <th>sum_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.56</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>244</td>\n",
       "      <td>4.39</td>\n",
       "      <td>13.56</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>This two line graphs illustrates monthly avera...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.43</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>175</td>\n",
       "      <td>6.29</td>\n",
       "      <td>25.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>﻿We have two graphics, which show us the popul...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   av_depth  max_depth  min_depth  num_acl  num_rel_cl  num_advcl  num_sent  \\\n",
       "0      3.56          6          2        2           0          1        18   \n",
       "1      5.43         10          4        1           3          1         7   \n",
       "\n",
       "   num_tok  av_tok_before_root  av_len_sent  ...  num_linkings  num_4grams  \\\n",
       "0      244                4.39        13.56  ...             5           1   \n",
       "1      175                6.29        25.00  ...             6           1   \n",
       "\n",
       "   num_func_ngrams  num_shell_noun  num_misspelled_tokens  million_mistake  \\\n",
       "0                0               0                      2                0   \n",
       "1                0               0                      3                0   \n",
       "\n",
       "                                                text  class  type  sum_punct  \n",
       "0  This two line graphs illustrates monthly avera...      6     1          0  \n",
       "1  ﻿We have two graphics, which show us the popul...      6     1          0  \n",
       "\n",
       "[2 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\hse_iot\\VKR\\my_inspector\\data\\classification_dataset.csv')\n",
    "df['class'] = round(df['class'] / 10).astype(int)\n",
    "df = df[df['class'] != 1]\n",
    "_type = df['type'].to_list()\n",
    "df = df.drop(['name', 'side_mistake',\n",
    "              'vs', 'squared_vs', 'ttr', 'root_ttr',\n",
    "              'log_ttr', 'uber_ttr', 'd', 'vvi',\n",
    "              'squared_vv', 'punct_mistakes_pp',\n",
    "              'punct_mistakes_because',\n",
    "              'punct_mistakes_but', 'punct_mistakes_compare'], axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    2680\n",
       "7     308\n",
       "5     215\n",
       "4     122\n",
       "8      77\n",
       "2      24\n",
       "3      14\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJoAAAJPCAYAAAA0Sr4gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoFElEQVR4nO3dbZCW5X338d/CApHobZTZZRhkaGNt1TiCoxVp7W7SxgWFLQq0RTSUtBp8KM7QDIqItZJGKOGWhlGskzGmkTaGWMGUIYuOHZkhYDW80JJRa8NDRmB2AfEBDMuyXPeLTPcuxRrQY7lY+Hxe7Xlc57Xnf1+4w349z+OqqVQqlQAAAADAJ9Sr2gMAAAAAcHIQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgiNpqD9Dd9uzZl0OHKtUeAwAAAKDH69WrJmed9en/9fWTPjQdOlQRmgAAAACOA4/OAQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUES3hqZvfvObueaaazJmzJg8/vjjSZJ169alubk5TU1NWbRoUde5r732WiZMmJBRo0blnnvuycGDB5Mk27dvzw033JDRo0fn1ltvzb59+7pzZAAAAAA+pm4LTS+99FJefPHF/PCHP8w///M/54knnsjrr7+e2bNnZ8mSJVm1alU2btyYNWvWJElmzpyZe++9N6tXr06lUsmyZcuSJPfff38mT56clpaWXHTRRVmyZEl3jQwAAADAJ9Btoenyyy/Pd7/73dTW1mb37t3p7OzMe++9l6FDh2bIkCGpra1Nc3NzWlpasm3btuzfvz/Dhw9PkowfPz4tLS3p6OjIyy+/nFGjRh22DgAAAMCJp1sfnevTp08WL16cMWPGZOTIkWlra0tdXV3X6/X19WltbT1iva6uLq2trdmzZ09OP/301NbWHrYOAAAAwImntrsvcMcdd+Tmm2/OLbfcki1bthzxek1NTSqVyjGtH4sBA04/pvMBAAAA+Hi6LTT97Gc/y4EDB3LBBRfktNNOS1NTU1paWtK7d++uc9ra2lJfX5+BAwdm165dXes7d+5MfX19zj777OzduzednZ3p3bt31/qx2L17bw4dOjJYAQAAAHBsevWq+ciberotNL311ltZvHhxvve97yVJnn/++UyaNCkLFizI1q1bc84552TlypWZMGFCBg8enH79+mXDhg259NJLs2LFijQ0NKRPnz657LLLsmrVqjQ3N3etAwDwyZz5mdPSt0+339wO/A8HOg7m3Xd+Ue0xALpNTeXDnk8rZPHixV13MTU1NWX69OlZv3595s2bl/b29jQ2Nubuu+9OTU1NXn/99cyZMyf79u3LhRdemHnz5qVv377Ztm1bZs2ald27d2fQoEF58MEHc+aZZx71DO5oAgA4Ul3dGVmydG21x4BTzm03XpmdO9+v9hgAH9uvuqOpW0PTiUBoAgA4ktAE1SE0AT3drwpN3fqpcwAAAACcOoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAiujW0PTQQw9lzJgxGTNmTBYsWJAkufvuu9PU1JRx48Zl3Lhxee6555Ik69atS3Nzc5qamrJo0aKu7/Haa69lwoQJGTVqVO65554cPHiwO0cGAAAA4GPqttC0bt26rF27NsuXL8+KFSvy05/+NM8991w2btyYpUuX5plnnskzzzyTq666Kvv378/s2bOzZMmSrFq1Khs3bsyaNWuSJDNnzsy9996b1atXp1KpZNmyZd01MgAAAACfQLeFprq6usyaNSt9+/ZNnz59cu6552b79u3Zvn177r333jQ3N2fx4sU5dOhQXn311QwdOjRDhgxJbW1tmpub09LSkm3btmX//v0ZPnx4kmT8+PFpaWnprpEBAAAA+ARqu+sbn3feeV1fb9myJatWrco//dM/5aWXXsrcuXPTv3//TJs2LU899VT69++furq6rvPr6+vT2tqatra2w9br6urS2tp6THMMGHD6J/9hAAAACqmrO6PaIwB0m24LTf/lzTffzLRp03LXXXfls5/9bB5++OGu1770pS9lxYoVGT169BHvq6mpSaVS+dD1Y7F7994cOnTk9wEAOJX5QxeqZ+fO96s9AsDH1qtXzUfe1NOtm4Fv2LAhU6dOzVe/+tVcd911eeONN7J69equ1yuVSmprazNw4MDs2rWra72trS319fVHrO/cuTP19fXdOTIAAAAAH1O3haYdO3bk9ttvz8KFCzNmzJgkvwxLDzzwQN599910dHTk+9//fq666qoMGzYsmzdvztatW9PZ2ZmVK1emoaEhgwcPTr9+/bJhw4YkyYoVK9LQ0NBdIwMAAADwCXTbo3OPPfZY2tvbM3/+/K61SZMm5Stf+Uquv/76HDx4ME1NTRk7dmySZP78+Zk+fXra29vT2NjY9TjdwoULM2fOnOzbty8XXnhhpkyZ0l0jAwAAAPAJ1FQ+bCOkk4g9mgAAjlRXd0aWLF1b7THglHPbjVfaowno0aq6RxMAAAAApw6hCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgiG4NTQ899FDGjBmTMWPGZMGCBUmSdevWpbm5OU1NTVm0aFHXua+99lomTJiQUaNG5Z577snBgweTJNu3b88NN9yQ0aNH59Zbb82+ffu6c2QAAAAAPqZuC03r1q3L2rVrs3z58qxYsSI//elPs3LlysyePTtLlizJqlWrsnHjxqxZsyZJMnPmzNx7771ZvXp1KpVKli1bliS5//77M3ny5LS0tOSiiy7KkiVLumtkAAAAAD6BbgtNdXV1mTVrVvr27Zs+ffrk3HPPzZYtWzJ06NAMGTIktbW1aW5uTktLS7Zt25b9+/dn+PDhSZLx48enpaUlHR0defnllzNq1KjD1gEAAAA48XRbaDrvvPO6wtGWLVuyatWq1NTUpK6uruuc+vr6tLa2pq2t7bD1urq6tLa2Zs+ePTn99NNTW1t72DoAAAAAJ57a7r7Am2++mWnTpuWuu+5KbW1tNm/efNjrNTU1qVQqR7zvo9aPxYABpx/bwAAAAN2oru6Mao8A0G26NTRt2LAhd9xxR2bPnp0xY8bkpZdeyq5du7peb2trS319fQYOHHjY+s6dO1NfX5+zzz47e/fuTWdnZ3r37t21fix2796bQ4eODFYAAKcyf+hC9ezc+X61RwD42Hr1qvnIm3q67dG5HTt25Pbbb8/ChQszZsyYJMmwYcOyefPmbN26NZ2dnVm5cmUaGhoyePDg9OvXLxs2bEiSrFixIg0NDenTp08uu+yyrFq16rB1AAAAAE483XZH02OPPZb29vbMnz+/a23SpEmZP39+pk+fnvb29jQ2Nmb06NFJkoULF2bOnDnZt29fLrzwwkyZMiVJct9992XWrFl55JFHMmjQoDz44IPdNTIAAAAAn0BN5cM2QjqJeHQOAOBIdXVnZMnStdUeA045t914pUfngB6tao/OAQAAAHBqEZoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAijiq0NTa2nrE2n/+538WHwYAAACAnusjQ9M777yTd955JzfffHPefffdruNdu3bltttuO14zAgAAANAD1H7Ui1/96lfz4x//OEkyYsSI//+m2tp88Ytf7N7JAAAAAOhRPjI0PfbYY0mSu+++O/PmzTsuAwEAAADQM31kaPov8+bNy7Zt2/Luu++mUql0rX/uc5/rtsEAAAAA6FmOKjQtXLgwTzzxRAYMGNC1VlNTk+eff77bBgMAAACgZzmq0LRq1ao8++yzGThwYHfPAwAAAEAP9ZGfOvdfBg0aJDIBAAAA8JGO6o6mkSNHZsGCBfmDP/iDfOpTn+pat0cTAAAAAP/lqELT008/nSRpaWnpWrNHEwAAAAD/3VGFpn/913/t7jkAAAAA6OGOKjQ9/vjjH7r+5S9/uegwAAAAAPRcRxWa/uM//qPr6wMHDmTDhg0ZMWJEtw0FAAAAQM9zVKFp3rx5hx2//fbbufPOO7tlIAAAAAB6pl4f501nn312tm3bVnoWAAAAAHqwY96jqVKpZOPGjRkwYEC3DQUAAABAz3PMezQlyaBBgzw6BwAAAMBhjmmPpm3btuXgwYMZOnRotw4FAAAAQM9zVKFp69atue2229LW1pZDhw7lrLPOyqOPPppzzz23u+cDAAAAoIc4qs3A586dm5tuuikvv/xyNmzYkFtvvTX3339/d88GAAAAQA9yVKFp9+7due6667qOJ0yYkD179nTbUAAAAAD0PEcVmjo7O/POO+90Hb/99ttHfYG9e/dm7Nixeeutt5Ikd999d5qamjJu3LiMGzcuzz33XJJk3bp1aW5uTlNTUxYtWtT1/tdeey0TJkzIqFGjcs899+TgwYNHfW0AAAAAjp+j2qPpxhtvzJ/8yZ/k6quvTpL86Ec/yp/+6Z/+yve98sormTNnTrZs2dK1tnHjxixdujT19fVda/v378/s2bPzxBNPZNCgQZk2bVrWrFmTxsbGzJw5M3/zN3+T4cOHZ/bs2Vm2bFkmT558jD8mAAAAAN3tqO5oamxsTJJ0dHRk06ZNaW1tzVVXXfUr37ds2bLcd999XVHpgw8+yPbt23Pvvfemubk5ixcvzqFDh/Lqq69m6NChGTJkSGpra9Pc3JyWlpZs27Yt+/fvz/Dhw5Mk48ePT0tLy8f8UQEAAADoTkd1R9OsWbNyww03ZMqUKWlvb8/3vve9zJ49O9/61rc+8n1f//rXDzvevXt3rrjiisydOzf9+/fPtGnT8tRTT6V///6pq6vrOq++vj6tra1pa2s7bL2uri6tra3H8vNlwIDTj+l8AACA7lRXd0a1RwDoNkcVmvbs2ZMpU6YkSfr165epU6dmxYoVx3yxIUOG5OGHH+46/tKXvpQVK1Zk9OjRR5xbU1OTSqXyoevHYvfuvTl06MjvAwBwKvOHLlTPzp3vV3sEgI+tV6+aj7yp56g3A//vdxLt2rXrQyPQr/LGG29k9erVXceVSiW1tbUZOHBgdu3a1bXe1taW+vr6I9Z37tx52N5OAAAAAJw4juqOpqlTp+baa6/N7/3e76Wmpibr1q3LnXfeecwXq1QqeeCBB3LFFVekf//++f73v5/rrrsuw4YNy+bNm7N169acc845WblyZSZMmJDBgwenX79+2bBhQy699NKsWLEiDQ0Nx3xdAAAAALrfUYWmiRMn5qKLLsqLL76Y3r1758///M/zm7/5m8d8sfPPPz9f+cpXcv311+fgwYNpamrK2LFjkyTz58/P9OnT097ensbGxq7H6RYuXJg5c+Zk3759ufDCC7se4QMAAADgxFJT+TjPwPUg9mgCADhSXd0ZWbJ0bbXHgFPObTdeaY8moEcrskcTAAAAAPwqQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFdGto2rt3b8aOHZu33norSbJu3bo0NzenqakpixYt6jrvtddey4QJEzJq1Kjcc889OXjwYJJk+/btueGGGzJ69Ojceuut2bdvX3eOCwAAAMAn0G2h6ZVXXsn111+fLVu2JEn279+f2bNnZ8mSJVm1alU2btyYNWvWJElmzpyZe++9N6tXr06lUsmyZcuSJPfff38mT56clpaWXHTRRVmyZEl3jQsAAADAJ9RtoWnZsmW57777Ul9fnyR59dVXM3To0AwZMiS1tbVpbm5OS0tLtm3blv3792f48OFJkvHjx6elpSUdHR15+eWXM2rUqMPWAQAAADgx1XbXN/76179+2HFbW1vq6uq6juvr69Pa2nrEel1dXVpbW7Nnz56cfvrpqa2tPWz9WA0YcPrH/AkAAADKq6s7o9ojAHSbbgtN/1OlUjliraam5pjXj9Xu3Xtz6NCR3wsA4FTmD12onp0736/2CAAfW69eNR95U89x+9S5gQMHZteuXV3HbW1tqa+vP2J9586dqa+vz9lnn529e/ems7PzsHUAAAAATkzHLTQNGzYsmzdvztatW9PZ2ZmVK1emoaEhgwcPTr9+/bJhw4YkyYoVK9LQ0JA+ffrksssuy6pVqw5bBwAAAODEdNwenevXr1/mz5+f6dOnp729PY2NjRk9enSSZOHChZkzZ0727duXCy+8MFOmTEmS3HfffZk1a1YeeeSRDBo0KA8++ODxGhcAAACAY1RT+bDNkE4i9mgCADhSXd0ZWbJ0bbXHgFPObTdeaY8moEc7YfZoAgAAAODkJjQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABQhNAEAAABQhNAEAAAAQBFCEwAAAABFCE0AAAAAFCE0AQAAAFCE0AQAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARQhMAAAAARQhNAAAAABRRW42LTpkyJbt3705t7S8vP3fu3Pz85z/PI488ko6OjkydOjU33HBDkmTdunWZN29e2tvbc/XVV2fGjBnVGBkAAACAX+G4h6ZKpZJNmzblhRde6ApNra2tmTFjRp5++un07ds3kyZNyogRI3LOOedk9uzZeeKJJzJo0KBMmzYta9asSWNj4/EeGwAAAIBf4biHpk2bNqWmpiY333xzdu/enT/+4z/Opz/96VxxxRX5zGc+kyQZNWpUWlpacvnll2fo0KEZMmRIkqS5uTktLS1CEwAAAMAJ6Ljv0fTee+9l5MiRefjhh/Od73wnTz75ZLZv3566urquc+rr69Pa2pq2trYPXQcAAADgxHPc72i65JJLcskllyRJ+vfvn4kTJ2bevHm55ZZbDjuvpqYmlUrliPfX1NQc0/UGDDj94w8LAABQWF3dGdUeAaDbHPfQ9JOf/CQdHR0ZOXJkkl/u2TR48ODs2rWr65y2trbU19dn4MCBH7p+LHbv3ptDh44MVgAApzJ/6EL17Nz5frVHAPjYevWq+cibeo77o3Pvv/9+FixYkPb29uzduzfLly/PN77xjaxfvz5vv/12fvGLX+TZZ59NQ0NDhg0bls2bN2fr1q3p7OzMypUr09DQcLxHBgAAAOAoHPc7mr7whS/klVdeybXXXptDhw5l8uTJufTSSzNjxoxMmTIlHR0dmThxYi6++OIkyfz58zN9+vS0t7ensbExo0ePPt4jAwAAAHAUaiofthHSScSjcwAAR6qrOyNLlq6t9hhwyrntxis9Ogf0aCfco3MAAAAAnJyEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAACiittoDAPDRzj6zX3r37VvtMeCU03ngQN5+t73aYwAA9ChCE8AJrnffvml75M5qjwGnnPpbFyQRmgAAjoVH5wAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkAAACAIoQmAAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCJqqz0AAAAAJ4ezzjwttX39mQnH28EDB7Pn3V9Ue4wkQhMAAACF1PatzX8+sqbaY8Ap5zdubaz2CF08OgcAAABAEUITAAAAAEUITQAAAAAUITQBAAAAUITQBAAAAEARPnWuoP/zmU+lX58+1R4DTjntHR1575391R4DAADglCc0FdSvT5989UffrfYYcMr5v1dPSSI0AQAAVJtH5wAAAAAookeEpn/5l3/JNddck6uuuir/+I//WO1xAAAAAPgQJ/yjc62trVm0aFGefvrp9O3bN5MmTcqIESPyG7/xG9UeDQAAAID/5oQPTevWrcsVV1yRz3zmM0mSUaNGpaWlJX/xF39xVO/v1aumG6c70lmnffq4Xg/4peP93/rx1uuMs6o9ApySTvbfLWd8ul+1R4BT0sn+u6X2DL9boBqO1++WX3WdmkqlUjkuk3xMjz76aD744IPMmDEjSfKDH/wgr776ar72ta9VeTIAAAAA/rsTfo+mD+tgNTUn9/8BAAAAAOiJTvjQNHDgwOzatavruK2tLfX19VWcCAAAAIAPc8KHpt/5nd/J+vXr8/bbb+cXv/hFnn322TQ0NFR7LAAAAAD+hxN+M/CBAwdmxowZmTJlSjo6OjJx4sRcfPHF1R4LAAAAgP/hhN8MHAAAAICe4YR/dA4AAACAnkFoAgAAAKAIoQkAAACAIoQmAAAAAIo44T91DrrbQw89lB/96EdJksbGxtx5551Vngg4GXzzm9/M6tWrU1NTk4kTJ+bLX/5ytUcCTiJ/+7d/mz179mT+/PnVHgU4CUyZMiW7d+9Obe0vE8HcuXMzbNiwKk9FTyU0cUpbt25d1q5dm+XLl6empiY33XRTnnvuuVx11VXVHg3owV566aW8+OKL+eEPf5iDBw/mmmuuSWNjYz772c9WezTgJLB+/fosX748n//856s9CnASqFQq2bRpU1544YWu0ASfhEfnOKXV1dVl1qxZ6du3b/r06ZNzzz0327dvr/ZYQA93+eWX57vf/W5qa2uze/fudHZ2pn///tUeCzgJvPPOO1m0aFFuueWWao8CnCQ2bdqUmpqa3HzzzfnDP/zDLF26tNoj0cPJlZzSzjvvvK6vt2zZklWrVuXJJ5+s4kTAyaJPnz5ZvHhxvv3tb2f06NEZOHBgtUcCTgJ/9Vd/lRkzZmTHjh3VHgU4Sbz33nsZOXJk/vqv/zr79+/PlClT8uu//uv53d/93WqPRg/ljiZI8uabb+bP/uzPctddd+XXfu3Xqj0OcJK44447sn79+uzYsSPLli2r9jhAD/eDH/wggwYNysiRI6s9CnASueSSS7JgwYL0798/Z599diZOnJg1a9ZUeyx6MHc0ccrbsGFD7rjjjsyePTtjxoyp9jjASeBnP/tZDhw4kAsuuCCnnXZampqa8sYbb1R7LKCHW7VqVXbu3Jlx48bl3XffzQcffJAHHnggs2fPrvZoQA/2k5/8JB0dHV0Ru1Kp2KuJT8QdTZzSduzYkdtvvz0LFy4UmYBi3nrrrcyZMycHDhzIgQMH8vzzz+fSSy+t9lhAD/f4449n5cqVeeaZZ3LHHXfk93//90Um4BN7//33s2DBgrS3t2fv3r1Zvny5D0fiE5EpOaU99thjaW9vP+yjgSdNmpTrr7++ilMBPV1jY2NeeeWVXHvttendu3eamprEbADghPSFL3yh698thw4dyuTJk3PJJZdUeyx6sJpKpVKp9hAAAAAA9HwenQMAAACgCKEJAAAAgCKEJgAAAACKEJoAAAAAKEJoAgAAAKAIoQkA4Dj4t3/7t4wdO7baYwAAdCuhCQAAAIAiaqs9AADAyeipp57K448/nl69euWss87K+PHju17bvHlz5s6dmw8++CBtbW05//zz83d/93fp169fFi9enOeeey59+vTJWWedlXnz5qW+vv5/XQcAOJEITQAAhb3++utZuHBhli9fnkGDBuU73/lO/v7v/z61tb/8p9eyZcty7bXXZty4ceno6Mj48ePzwgsv5OKLL84//MM/ZP369enbt2++/e1v59VXX83nPve5D13/4he/WOWfFADgcEITAEBh69evz5VXXplBgwYlSaZOnZoLLrggX/va15IkM2fOzI9//ON861vfypYtW9LW1pYPPvggAwcOzPnnn5/rrrsuDQ0NaWhoyMiRI3Po0KEPXQcAONEITQAAhfXu3Ts1NTVdx/v378+mTZu6jv/yL/8ynZ2dufrqq/P5z38+O3bsSKVSSa9evbJ06dL8+7//e9avX58HHnggI0aMyJw5c/7XdQCAE4nNwAEAChsxYkTWr1+ftra2JMmTTz6Zb3zjG12vr127Nrfffnuuueaa1NTU5JVXXklnZ2def/31jB07Nueee26mTZuWqVOn5o033vhf1wEATjTuaAIAKOy3fuu3MnPmzNx0001Jkrq6utx///159NFHkyQzZszI7bffnjPPPDOnnXZafvu3fzs///nP80d/9Ee5+uqrM2HChPTv3z+f+tSnMmfOnJx//vkfug4AcKKpqVQqlWoPAQAAAEDP59E5AAAAAIoQmgAAAAAoQmgCAAAAoAihCQAAAIAihCYAAAAAihCaAAAAAChCaAIAAACgCKEJAAAAgCL+H9PycnfbQUqOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[df['class'] == 1, 'class'] = 2\n",
    "df.loc[df['class'] == 3, 'class'] = 2\n",
    "df.loc[df['class'] == 4, 'class'] = 3\n",
    "df.loc[df['class'] == 5, 'class'] = 3\n",
    "df.loc[df['class'] == 6, 'class'] = 4\n",
    "df.loc[df['class'] == 7, 'class'] = 4\n",
    "df.loc[df['class'] == 8, 'class'] = 5\n",
    "\n",
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "sns_plt = sns.countplot(x='class', data=df, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'class': 'cls'})\n",
    "feature_columns = [col for col in df.columns if col not in ['cls',]]\n",
    "X = df[feature_columns]\n",
    "y = df['cls']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. имеем очень малое количество текстов во всех классах кроме 4, то сгенерируем тексты скомпоновав их половины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>av_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>num_acl</th>\n",
       "      <th>num_rel_cl</th>\n",
       "      <th>num_advcl</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>num_tok</th>\n",
       "      <th>av_tok_before_root</th>\n",
       "      <th>av_len_sent</th>\n",
       "      <th>...</th>\n",
       "      <th>num_pres_plur</th>\n",
       "      <th>num_past_part</th>\n",
       "      <th>num_past_simple</th>\n",
       "      <th>num_linkings</th>\n",
       "      <th>num_4grams</th>\n",
       "      <th>num_func_ngrams</th>\n",
       "      <th>million_mistake</th>\n",
       "      <th>text</th>\n",
       "      <th>sum_punct</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.69</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>189</td>\n",
       "      <td>4.23</td>\n",
       "      <td>14.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The graph illustrates the market situation abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.93</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>244</td>\n",
       "      <td>4.80</td>\n",
       "      <td>16.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There is a linegraph and piechart. The linegra...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     av_depth  max_depth  min_depth  num_acl  num_rel_cl  num_advcl  num_sent  \\\n",
       "idx                                                                             \n",
       "0        3.69          7          2        2           2          0        13   \n",
       "1        3.93          7          2        1           3          1        15   \n",
       "\n",
       "     num_tok  av_tok_before_root  av_len_sent  ...  num_pres_plur  \\\n",
       "idx                                            ...                  \n",
       "0        189                4.23        14.54  ...              0   \n",
       "1        244                4.80        16.27  ...              0   \n",
       "\n",
       "     num_past_part  num_past_simple  num_linkings  num_4grams  \\\n",
       "idx                                                             \n",
       "0                2                4             6           3   \n",
       "1                3                0            13           2   \n",
       "\n",
       "     num_func_ngrams  million_mistake  \\\n",
       "idx                                     \n",
       "0                  1                0   \n",
       "1                  0                0   \n",
       "\n",
       "                                                  text  sum_punct  cls  \n",
       "idx                                                                     \n",
       "0    The graph illustrates the market situation abo...          0    4  \n",
       "1    There is a linegraph and piechart. The linegra...          0    4  \n",
       "\n",
       "[2 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen = pd.read_csv(r'D:\\hse_iot\\VKR\\my_inspector\\data\\generated_data.csv', index_col='idx')\n",
    "df_gen.drop(['squared_vs', 'root_ttr', 'uber_ttr', 'ttr', 'd', 'vvi', 'squared_vv', 'vs', 'log_ttr'],  inplace=True, axis=1)\n",
    "df_gen.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The pie charts provide the information about transportation of different goods between east Europe countries in 2008. One pie chart is about goods transported by rail another by road.\\r\\n\\r\\nIt can be seen that metals are often transported by rail it is 35%. And the most transported by road is a food products. Form the charts it is clear that the way of chemicals transportation is not very important, because numbers are fast the same. What about machinery it prefer to transport by rail and only 2% of machinery goods are transported by road. Non-metallic minerals is better to transport by road. Comparing two pie charts it can be see that both ways of transportation are popular and the choice hangs what kind of goods need to transport the most convenient way to metals transportations is rail, and to food products transportation is road. Machinery goods are transported by road seldom.\\r\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen.text.iloc[157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2441\n",
       "4    2386\n",
       "3    2257\n",
       "2    2016\n",
       "Name: cls, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen['cls'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "sns_plt = sns.countplot(x='cls', data=df_gen, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(clf, train_x, train_y, test_x, test_y):\n",
    "    print('         -----------Train data res------------\\n')\n",
    "    pred_y = cross_val_predict(clf, train_x, train_y, cv=10)\n",
    "    print(classification_report(train_y, pred_y))\n",
    "    print('Confusion matrix: \\n\\n', confusion_matrix(train_y, pred_y))\n",
    "    \n",
    "    print('\\n       -----------Test data res------------\\n')\n",
    "    clf.fit(train_x, train_y)\n",
    "    pred_y = clf.predict(test_x)\n",
    "    print(classification_report(test_y, pred_y))\n",
    "    print('Confusion matrix: \\n\\n', confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cтатистические модели на половинах текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [i for i in df_gen.columns if i not in ['cls', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -----------Train data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.81      0.85      0.83      2016\n",
      "           3       0.76      0.62      0.68      2257\n",
      "           4       0.88      0.98      0.93      2386\n",
      "           5       0.86      0.88      0.87      2441\n",
      "\n",
      "    accuracy                           0.84      9100\n",
      "   macro avg       0.83      0.83      0.83      9100\n",
      "weighted avg       0.83      0.84      0.83      9100\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[1721  211    0   84]\n",
      " [ 390 1390  222  255]\n",
      " [   5   30 2346    5]\n",
      " [  12  190   87 2152]]\n",
      "\n",
      "       -----------Test data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.33      0.25      0.29         8\n",
      "           3       0.86      0.50      0.63        76\n",
      "           4       0.92      0.99      0.95       587\n",
      "           5       0.83      0.29      0.43        17\n",
      "\n",
      "    accuracy                           0.91       688\n",
      "   macro avg       0.74      0.51      0.58       688\n",
      "weighted avg       0.91      0.91      0.90       688\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[  2   2   4   0]\n",
      " [  4  38  34   0]\n",
      " [  0   4 582   1]\n",
      " [  0   0  12   5]]\n"
     ]
    }
   ],
   "source": [
    "get_results(KNeighborsClassifier(n_neighbors=7, p=1, weights='distance'),\n",
    "           df_gen[feature_cols],\n",
    "           df_gen['cls'],\n",
    "           test_x[feature_cols],\n",
    "           test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7, p=1, weights='distance')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7, p=1, weights='distance')\n",
    "knn.fit(df_gen[feature_cols], df_gen['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>av_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>num_acl</th>\n",
       "      <th>num_rel_cl</th>\n",
       "      <th>num_advcl</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>num_tok</th>\n",
       "      <th>av_tok_before_root</th>\n",
       "      <th>av_len_sent</th>\n",
       "      <th>...</th>\n",
       "      <th>num_past_simple</th>\n",
       "      <th>num_linkings</th>\n",
       "      <th>num_4grams</th>\n",
       "      <th>num_func_ngrams</th>\n",
       "      <th>num_shell_noun</th>\n",
       "      <th>num_misspelled_tokens</th>\n",
       "      <th>million_mistake</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>sum_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>4.35</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>323</td>\n",
       "      <td>5.41</td>\n",
       "      <td>19.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>It is a well known fact that people today have...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>5.78</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>208</td>\n",
       "      <td>4.56</td>\n",
       "      <td>23.11</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>This chart as we can see characterized how muc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>5.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>303</td>\n",
       "      <td>4.21</td>\n",
       "      <td>21.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>With the industrialisation and modernisation o...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>3.12</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>312</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Technologies are an essential part of modern l...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>5.07</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>321</td>\n",
       "      <td>6.64</td>\n",
       "      <td>22.93</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>At present there is a trend of air travel, tha...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>5.78</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>225</td>\n",
       "      <td>9.67</td>\n",
       "      <td>25.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>﻿To start with, we live in the deloping world ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>4.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>5.67</td>\n",
       "      <td>15.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Today the most of people every day use technol...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>3.12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>207</td>\n",
       "      <td>6.06</td>\n",
       "      <td>12.94</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>The chart shows changes in the unemployment ra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>5.33</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>237</td>\n",
       "      <td>6.56</td>\n",
       "      <td>26.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>﻿The bar chart illustrates the distribution of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>5.21</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>313</td>\n",
       "      <td>5.07</td>\n",
       "      <td>22.36</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Nowadays air travel is becoming more and more ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      av_depth  max_depth  min_depth  num_acl  num_rel_cl  num_advcl  \\\n",
       "265       4.35          7          2        6           6          6   \n",
       "1009      5.78          9          2        2           2          5   \n",
       "1130      5.00          7          2        5           1          9   \n",
       "579       3.12          5          2        0           0          4   \n",
       "1665      5.07          9          3        5           3          6   \n",
       "...        ...        ...        ...      ...         ...        ...   \n",
       "725       5.78          8          3        4           4          5   \n",
       "1964      4.00          7          2        2           1          1   \n",
       "3331      3.12          4          2        4           0          3   \n",
       "207       5.33          9          2        7           3          5   \n",
       "1643      5.21          9          2        3           5          9   \n",
       "\n",
       "      num_sent  num_tok  av_tok_before_root  av_len_sent  ...  \\\n",
       "265         17      323                5.41        19.00  ...   \n",
       "1009         9      208                4.56        23.11  ...   \n",
       "1130        14      303                4.21        21.64  ...   \n",
       "579         26      312                3.12        12.00  ...   \n",
       "1665        14      321                6.64        22.93  ...   \n",
       "...        ...      ...                 ...          ...  ...   \n",
       "725          9      225                9.67        25.00  ...   \n",
       "1964         6       91                5.67        15.17  ...   \n",
       "3331        16      207                6.06        12.94  ...   \n",
       "207          9      237                6.56        26.33  ...   \n",
       "1643        14      313                5.07        22.36  ...   \n",
       "\n",
       "      num_past_simple  num_linkings  num_4grams  num_func_ngrams  \\\n",
       "265                 4            18           8                2   \n",
       "1009                3             4           6                1   \n",
       "1130                1            15           5                2   \n",
       "579                 6            13          22                5   \n",
       "1665                2             9          21                4   \n",
       "...               ...           ...         ...              ...   \n",
       "725                 2            11           9                2   \n",
       "1964                2             3           0                0   \n",
       "3331                2             9           0                0   \n",
       "207                 1            12           4                1   \n",
       "1643                1            12          13                2   \n",
       "\n",
       "      num_shell_noun  num_misspelled_tokens  million_mistake  \\\n",
       "265                8                      4                0   \n",
       "1009               1                     11               10   \n",
       "1130               6                      2                0   \n",
       "579                3                      2                0   \n",
       "1665               4                      1                0   \n",
       "...              ...                    ...              ...   \n",
       "725                2                      6                0   \n",
       "1964               1                      1                0   \n",
       "3331               0                      5                0   \n",
       "207                0                      7                0   \n",
       "1643               4                      3                0   \n",
       "\n",
       "                                                   text  type  sum_punct  \n",
       "265   It is a well known fact that people today have...     2          1  \n",
       "1009  This chart as we can see characterized how muc...     1          0  \n",
       "1130  With the industrialisation and modernisation o...     2          1  \n",
       "579   Technologies are an essential part of modern l...     2          0  \n",
       "1665  At present there is a trend of air travel, tha...     2          1  \n",
       "...                                                 ...   ...        ...  \n",
       "725   ﻿To start with, we live in the deloping world ...     2          1  \n",
       "1964  Today the most of people every day use technol...     2          0  \n",
       "3331  The chart shows changes in the unemployment ra...     1          1  \n",
       "207   ﻿The bar chart illustrates the distribution of...     1          0  \n",
       "1643  Nowadays air travel is becoming more and more ...     2          2  \n",
       "\n",
       "[688 rows x 61 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe bar chart illustrates the proportion of the usage of three social networks by adults belonging to different age groups in the United States.\\r\\n\\r\\nIt can be clearly seen that Facebook is the most popular online network among all age groups, with more than four-fifth of people aged from 18 to 29 and more than a half of the people from other age groups using it.\\r\\nOn the contrary, Instagram and LinkedIn are not as widely used. While slightly more than a half of the younger generation have an Instagram account, only a quarter of people aged from 30 to 49 communicate via this network. As for those who are 50 years old or more, Instagram users make up a small minority.\\r\\nThe difference in the percentage of those who have LinkedIn accounts is less dramatic. The proportion of users aged from 18 to 29 and those who are at least 65 years old is equal, making up 22 per cent. The figures for those who belong to other age groups, 30-49 and 50-64 years old, are almost identical, with 31 and 32 per cent respectively.\\r\\n\\r\\nOverall, it can be concluded that Facebook is preferred to other social networks by all age groups in the USA, whereas Instagram is used mostly by younger people and LinkedIn popular among approximately a quarter of the whole adult population.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[test_y == 5].text.to_list()[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'It is a well known fact that people today have a lot of problems with their health because of the use of computers and other technologied devices. Some of this problems are very serious, some of them can be easily reduced. \\r\\n\\r\\nThe most common problem for people nowadays is the lack of mobility. We spend a great part of the day sitting by our computers. People who work sit near the computer almost 8 hours without even getting up. Even students who are supposed to be healthy and active suffer from this problem. To reduce this issue, special exercises brakes can be introduced in offices, maybe even in universities and schools. It is crucial to have some resting time during work and studying, but it’s also important for this break to be helpful physically and mentaly. And of course let’s not forget about the healthy diet a person should have and the importance of staying hidrated. \\r\\n\\r\\nAnother problem that is discussed a lot today is peoples’ dependence on mobile phones and the internet.  A lot of my friends agree that they can’t live without  their phones. The constant need of communication and information stays behind that. However, I think that sometimes we need to have some tome for ourselves. Therefore one of the ways of dealing with this particular problem would be meditation. It is an easy way to relax and ger yourself together, clear  your head from all the unnecessary information that comes to us everyday. In my opinion, this is a great habbit everybody can develop. \\r\\n\\r\\nTo conclude, I can say that despite the fact that we live in a world  full of modern technology, we shouldn’t be lazy and we shouldn’t forget to take care of our personal health.\\r\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-aaedbedf19b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \"\"\"\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'It is a well known fact that people today have a lot of problems with their health because of the use of computers and other technologied devices. Some of this problems are very serious, some of them can be easily reduced. \\r\\n\\r\\nThe most common problem for people nowadays is the lack of mobility. We spend a great part of the day sitting by our computers. People who work sit near the computer almost 8 hours without even getting up. Even students who are supposed to be healthy and active suffer from this problem. To reduce this issue, special exercises brakes can be introduced in offices, maybe even in universities and schools. It is crucial to have some resting time during work and studying, but it’s also important for this break to be helpful physically and mentaly. And of course let’s not forget about the healthy diet a person should have and the importance of staying hidrated. \\r\\n\\r\\nAnother problem that is discussed a lot today is peoples’ dependence on mobile phones and the internet.  A lot of my friends agree that they can’t live without  their phones. The constant need of communication and information stays behind that. However, I think that sometimes we need to have some tome for ourselves. Therefore one of the ways of dealing with this particular problem would be meditation. It is an easy way to relax and ger yourself together, clear  your head from all the unnecessary information that comes to us everyday. In my opinion, this is a great habbit everybody can develop. \\r\\n\\r\\nTo conclude, I can say that despite the fact that we live in a world  full of modern technology, we shouldn’t be lazy and we shouldn’t forget to take care of our personal health.\\r\\n'"
     ]
    }
   ],
   "source": [
    "knn.predict(test_x[feat])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -----------Train data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.93      0.93      0.93      2016\n",
      "           3       0.88      0.79      0.83      2257\n",
      "           4       0.87      0.99      0.93      2386\n",
      "           5       0.94      0.90      0.92      2441\n",
      "\n",
      "    accuracy                           0.90      9100\n",
      "   macro avg       0.90      0.90      0.90      9100\n",
      "weighted avg       0.90      0.90      0.90      9100\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[1867  117    1   31]\n",
      " [ 145 1783  225  104]\n",
      " [   1   22 2358    5]\n",
      " [   3  115  114 2209]]\n",
      "\n",
      "       -----------Test data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.50      0.25      0.33         8\n",
      "           3       0.83      0.46      0.59        76\n",
      "           4       0.91      0.99      0.95       587\n",
      "           5       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.90       688\n",
      "   macro avg       0.56      0.42      0.47       688\n",
      "weighted avg       0.87      0.90      0.88       688\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[  2   2   4   0]\n",
      " [  2  35  39   0]\n",
      " [  0   5 580   2]\n",
      " [  0   0  17   0]]\n"
     ]
    }
   ],
   "source": [
    "get_results(RandomForestClassifier(max_depth=33, max_features='sqrt', min_samples_split=7, n_estimators=702),\n",
    "           df_gen[feature_cols],\n",
    "           df_gen['cls'],\n",
    "           test_x[feature_cols],\n",
    "           test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -----------Train data res------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:03:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:03:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:03:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:04:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:04:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:05:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:05:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:06:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.93      0.92      0.93      2016\n",
      "           3       0.88      0.79      0.83      2257\n",
      "           4       0.87      0.99      0.93      2386\n",
      "           5       0.94      0.91      0.93      2441\n",
      "\n",
      "    accuracy                           0.91      9100\n",
      "   macro avg       0.91      0.90      0.90      9100\n",
      "weighted avg       0.91      0.91      0.90      9100\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[1864  125    1   26]\n",
      " [ 146 1779  229  103]\n",
      " [   0   15 2366    5]\n",
      " [   4   95  113 2229]]\n",
      "\n",
      "       -----------Test data res------------\n",
      "\n",
      "[15:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.50      0.25      0.33         8\n",
      "           3       0.87      0.43      0.58        76\n",
      "           4       0.90      0.99      0.95       587\n",
      "           5       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.90       688\n",
      "   macro avg       0.57      0.42      0.46       688\n",
      "weighted avg       0.87      0.90      0.87       688\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[  2   2   4   0]\n",
      " [  2  33  41   0]\n",
      " [  0   3 582   2]\n",
      " [  0   0  17   0]]\n"
     ]
    }
   ],
   "source": [
    "get_results(xgb.XGBRFClassifier(colsample_bytree=0.4,\n",
    "                gamma=0.1,\n",
    "                learning_rate=0.3,\n",
    "                max_depth=12,\n",
    "                min_child_weight=1,\n",
    "                n_estimators=638,\n",
    "                reg_alpha=0,\n",
    "                reg_lambda=0.01,\n",
    "                subsample=1),\n",
    "           df_gen[feature_cols],\n",
    "           df_gen['cls'],\n",
    "           test_x[feature_cols],\n",
    "           test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -----------Train data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.80      0.80      0.80      2016\n",
      "           3       0.70      0.63      0.67      2257\n",
      "           4       0.88      0.99      0.93      2386\n",
      "           5       0.88      0.85      0.87      2441\n",
      "\n",
      "    accuracy                           0.82      9100\n",
      "   macro avg       0.82      0.82      0.82      9100\n",
      "weighted avg       0.82      0.82      0.82      9100\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[1605  340    2   69]\n",
      " [ 401 1432  222  202]\n",
      " [   3   10 2369    4]\n",
      " [   5  261   98 2077]]\n",
      "\n",
      "       -----------Test data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.43      0.38      0.40         8\n",
      "           3       0.70      0.09      0.16        76\n",
      "           4       0.87      1.00      0.93       587\n",
      "           5       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       688\n",
      "   macro avg       0.50      0.37      0.37       688\n",
      "weighted avg       0.83      0.86      0.82       688\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[  3   1   4   0]\n",
      " [  4   7  65   0]\n",
      " [  0   2 585   0]\n",
      " [  0   0  17   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_results(SVC(C=5,\n",
    "                class_weight='balanced',\n",
    "                decision_function_shape='ovr',\n",
    "                gamma='scale',\n",
    "                kernel='rbf'),\n",
    "           df_gen[feature_cols],\n",
    "           df_gen['cls'],\n",
    "           test_x[feature_cols],\n",
    "           test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('knn', KNeighborsClassifier(n_neighbors=7, p=1, weights='distance')),\n",
    "              ('rf', RandomForestClassifier(max_depth=33, max_features='sqrt', min_samples_split=7, n_estimators=702)),\n",
    "              ('xgb', xgb.XGBRFClassifier(colsample_bytree=0.4,\n",
    "                gamma=0.1,\n",
    "                learning_rate=0.3,\n",
    "                max_depth=12,\n",
    "                min_child_weight=1,\n",
    "                n_estimators=638,\n",
    "                reg_alpha=0,\n",
    "                reg_lambda=0.01,\n",
    "                subsample=1)),\n",
    "              ('svm', SVC(C=5,\n",
    "                class_weight='balanced',\n",
    "                decision_function_shape='ovr',\n",
    "                gamma='scale',\n",
    "                kernel='rbf'))]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator= RandomForestClassifier(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -----------Train data res------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.93      0.94      0.93      2016\n",
      "           3       0.91      0.80      0.85      2257\n",
      "           4       0.88      0.99      0.93      2386\n",
      "           5       0.96      0.92      0.94      2441\n",
      "\n",
      "    accuracy                           0.92      9100\n",
      "   macro avg       0.92      0.91      0.91      9100\n",
      "weighted avg       0.92      0.92      0.91      9100\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[1894  101    2   19]\n",
      " [ 135 1810  234   78]\n",
      " [   0   10 2370    6]\n",
      " [  12   74  102 2253]]\n",
      "\n",
      "       -----------Test data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.50      0.25      0.33         8\n",
      "           3       0.83      0.20      0.32        76\n",
      "           4       0.88      0.99      0.94       587\n",
      "           5       0.50      0.12      0.19        17\n",
      "\n",
      "    accuracy                           0.88       688\n",
      "   macro avg       0.68      0.39      0.44       688\n",
      "weighted avg       0.86      0.88      0.84       688\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[  2   2   4   0]\n",
      " [  2  15  59   0]\n",
      " [  0   1 584   2]\n",
      " [  0   0  15   2]]\n"
     ]
    }
   ],
   "source": [
    "get_results(clf,\n",
    "           df_gen[feature_cols],\n",
    "           df_gen['cls'],\n",
    "           test_x[feature_cols],\n",
    "           test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('knn', KNeighborsClassifier(n_neighbors=7, p=1, weights='distance')),\n",
    "              ('rf', RandomForestClassifier(max_depth=33, max_features='sqrt', min_samples_split=7, n_estimators=702)),\n",
    "              ('xgb', xgb.XGBRFClassifier(colsample_bytree=0.4,\n",
    "                gamma=0.1,\n",
    "                learning_rate=0.3,\n",
    "                max_depth=12,\n",
    "                min_child_weight=1,\n",
    "                n_estimators=638,\n",
    "                reg_alpha=0,\n",
    "                reg_lambda=0.01,\n",
    "                subsample=1)),\n",
    "              ('svm', SVC(C=5,\n",
    "                class_weight='balanced',\n",
    "                decision_function_shape='ovr',\n",
    "                gamma='scale',\n",
    "                kernel='rbf',\n",
    "                probability = True))]\n",
    "clf = VotingClassifier(estimators=estimators, voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -----------Train data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.86      0.87      0.86      2016\n",
      "           3       0.81      0.70      0.75      2257\n",
      "           4       0.88      0.99      0.93      2386\n",
      "           5       0.90      0.90      0.90      2441\n",
      "\n",
      "    accuracy                           0.87      9100\n",
      "   macro avg       0.86      0.86      0.86      9100\n",
      "weighted avg       0.86      0.87      0.86      9100\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[1752  190    0   74]\n",
      " [ 278 1579  225  175]\n",
      " [   3   19 2358    6]\n",
      " [   3  151   96 2191]]\n",
      "\n",
      "       -----------Test data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.40      0.25      0.31         8\n",
      "           3       0.89      0.45      0.60        76\n",
      "           4       0.91      0.99      0.95       587\n",
      "           5       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.90       688\n",
      "   macro avg       0.55      0.42      0.46       688\n",
      "weighted avg       0.88      0.90      0.88       688\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[  2   2   4   0]\n",
      " [  3  34  39   0]\n",
      " [  0   2 584   1]\n",
      " [  0   0  17   0]]\n"
     ]
    }
   ],
   "source": [
    "get_results(clf,\n",
    "           df_gen[feature_cols],\n",
    "           df_gen['cls'],\n",
    "           test_x[feature_cols],\n",
    "           test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prp2bin_clf(train_data, test_y, cls):\n",
    "    train_data_res = train_data.copy()\n",
    "    test_y_res = test_y.copy()\n",
    "    \n",
    "    train_data_res.loc[train_data_res['cls'] != cls, 'cls'] = 0\n",
    "    train_data_res.loc[train_data_res['cls'] == cls, 'cls'] = 1\n",
    "    \n",
    "    test_y_res.loc[test_y_res != cls] = 0\n",
    "    test_y_res.loc[test_y_res == cls] = 1\n",
    "    \n",
    "    return train_data_res, test_y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "data_dict[2] = prp2bin_clf(df_gen, test_y, 2)\n",
    "data_dict[3] = prp2bin_clf(df_gen, test_y, 3)\n",
    "data_dict[4] = prp2bin_clf(df_gen, test_y, 4)\n",
    "data_dict[5] = prp2bin_clf(df_gen, test_y, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dict = {}\n",
    "\n",
    "clf_dict[2] = RandomForestClassifier(max_depth=30, max_features='sqrt', min_samples_leaf=2,\n",
    "                                     min_samples_split=6, n_estimators=757)\n",
    "clf_dict[3] = SVC(C=990, class_weight='balanced', decision_function_shape='ovo', gamma=0.1,\n",
    "                  max_iter=10000)\n",
    "clf_dict[4] = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "clf_dict[5] = KNeighborsClassifier(n_neighbors=7, p=1, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bin_clf():\n",
    "    # train_acc: 2 = 89, 3 = 75, 4 = 96, 5 = 86\n",
    "    \n",
    "    def __init__(self, train_data, test_x, test_y, clf_dict):\n",
    "        self.clf_2 = clf_dict[2]\n",
    "        self.clf_3 = clf_dict[3]\n",
    "        self.clf_4 = clf_dict[4]\n",
    "        self.clf_5 = clf_dict[5]\n",
    "        \n",
    "        self.feature_cols = [i for i in train_data.columns if i not in ['cls', 'text']]\n",
    "        \n",
    "        def prp2bin_clf(train_data, test_y, cls):\n",
    "            train_data_res = train_data.copy()\n",
    "            test_y_res = test_y.copy()\n",
    "    \n",
    "            train_data_res.loc[train_data_res['cls'] != cls, 'cls'] = 0\n",
    "            train_data_res.loc[train_data_res['cls'] == cls, 'cls'] = 1\n",
    "    \n",
    "            test_y_res.loc[test_y_res != cls] = 0\n",
    "            test_y_res.loc[test_y_res == cls] = 1\n",
    "    \n",
    "            return train_data_res, test_y_res\n",
    "        \n",
    "        self.train_2, self.test_y_2 = prp2bin_clf(train_data, test_y, 2)\n",
    "        self.train_3, self.test_y_3 = prp2bin_clf(train_data, test_y, 3)\n",
    "        self.train_4, self.test_y_4 = prp2bin_clf(train_data, test_y, 4)\n",
    "        self.train_5, self.test_y_5 = prp2bin_clf(train_data, test_y, 5)\n",
    "        \n",
    "        self.train_x_2 = self.train_2[self.feature_cols]\n",
    "        self.train_x_3 = self.train_3[self.feature_cols]\n",
    "        self.train_x_4 = self.train_4[self.feature_cols]\n",
    "        self.train_x_5 = self.train_5[self.feature_cols]\n",
    "        \n",
    "        self.train_y_2 = self.train_2.cls\n",
    "        self.train_y_3 = self.train_3.cls\n",
    "        self.train_y_4 = self.train_4.cls\n",
    "        self.train_y_5 = self.train_5.cls\n",
    "        \n",
    "        self.test_x = test_x[self.feature_cols]\n",
    "        self.test_y = test_y\n",
    "    \n",
    "    def fit(self):\n",
    "        self.clf_2.fit(self.train_x_2, self.train_y_2)\n",
    "        self.clf_3.fit(self.train_x_3, self.train_y_3)\n",
    "        self.clf_4.fit(self.train_x_4, self.train_y_4)\n",
    "        self.clf_5.fit(self.train_x_5, self.train_y_5)\n",
    "    \n",
    "    def predict(self):\n",
    "        pred_y_4_df = pd.DataFrame(self.clf_4.predict(self.test_x), index=self.test_x.index, columns=['res',])\n",
    "        res = pred_y_4_df[pred_y_4_df['res'].isin([1,])]\n",
    "        res = res.replace(1, 4)\n",
    "        test_x_2 = self.test_x.loc[pred_y_4_df[pred_y_4_df['res'].isin([0,])].index]\n",
    "        \n",
    "        pred_y_2_df = pd.DataFrame(self.clf_2.predict(test_x_2), index=test_x_2.index, columns=['res',])\n",
    "        res = pd.concat([res, pred_y_2_df[pred_y_2_df['res'].isin([1,])]], ignore_index=False)\n",
    "        res = res.replace(1, 2)\n",
    "        test_x_5 = test_x_2.loc[pred_y_2_df[pred_y_2_df['res'].isin([0,])].index]\n",
    "        \n",
    "        pred_y_5_df = pd.DataFrame(self.clf_5.predict(test_x_5), index=test_x_5.index, columns=['res',])\n",
    "        res = pd.concat([res, pred_y_5_df[pred_y_5_df['res'].isin([1,])]], ignore_index=False)\n",
    "        res = res.replace(1, 5)\n",
    "        \n",
    "        rest = pred_y_5_df[pred_y_5_df['res'].isin([0,])]\n",
    "        pred_y_3_df = pd.DataFrame([3 for i in range(rest.index.shape[0])], index=rest.index, columns=['res',])\n",
    "        res = pd.concat([res, pred_y_3_df], ignore_index=False)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_clf = Bin_clf(df_gen, test_x, test_y, clf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    }
   ],
   "source": [
    "bin_clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    632\n",
       "3     46\n",
       "5      6\n",
       "2      4\n",
       "Name: res, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_bin = bin_clf.predict()\n",
    "pred_y_bin.res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.15      0.09      0.11        76\n",
      "           4       0.86      0.92      0.89       587\n",
      "           5       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80       688\n",
      "   macro avg       0.25      0.25      0.25       688\n",
      "weighted avg       0.75      0.80      0.77       688\n",
      "\n",
      "[[  0   0   4   0]\n",
      " [  2   7  37   0]\n",
      " [  6  68 541  17]\n",
      " [  0   1   5   0]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y_bin))\n",
    "print(confusion_matrix(pred_y_bin, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shelve.open('data\\\\w2v_wiki', flag='r') as w2v_file:\n",
    "    w2v = w2v_file['w2v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2V( BaseEstimator, TransformerMixin ):\n",
    "    def __init__( self):\n",
    "        with shelve.open('data\\\\w2v_wiki', flag='r') as w2v_file:\n",
    "            self.w2v = w2v_file['w2v']\n",
    "        self.index2word_set = set(self.w2v.index2word)\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def text_to_words(self, text):\n",
    "        model = Model(r'D:\\hse_iot\\VKR\\my_inspector\\inspector\\app\\data\\models\\english-partut-ud-2.3-181115.udpipe')\n",
    "        gf = get_feature_values.GetFeatures(model)\n",
    "        gf.get_info(text)\n",
    "        \n",
    "        words = []\n",
    "        for sent in gf.sentences:\n",
    "            sent_list = []\n",
    "            for word in sent:\n",
    "                lemma = word.get('lemma')\n",
    "                if re.sub('[^a-zA-Zа-яА-яёЁ]', '', lemma) != '':\n",
    "                    sent_list.append(lemma)\n",
    "            words.extend(sent_list)\n",
    "        return words\n",
    "    \n",
    "    def text_to_vec(self, text):\n",
    "        text_vec = np.zeros((self.w2v.vector_size,), dtype=\"float32\")\n",
    "        n_words = 0\n",
    "        \n",
    "        for word in self.text_to_words(text):\n",
    "            if word in self.index2word_set:\n",
    "                n_words = n_words + 1\n",
    "                text_vec = np.add(text_vec, self.w2v[word]) \n",
    "        \n",
    "        if n_words != 0:\n",
    "            text_vec /= n_words\n",
    "        return text_vec\n",
    "    \n",
    "    def transform( self, X, y = None ):\n",
    "        w2v_vectors = [self.text_to_vec(text) for text in X.text]\n",
    "        w2v_vectors_df = pd.DataFrame([i for i in w2v_vectors], columns=['w2v_' + str(i) for i in range(w2v_vectors[0].shape[0])])\n",
    "        w2v_vectors_df.index = X.index\n",
    "        X = X.join(w2v_vectors_df)\n",
    "    \n",
    "        return X.drop('text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_W2V = Pipeline(steps=[('data_W2V', W2V()),\n",
    "                          ('clf', KNeighborsClassifier(n_neighbors=7, p=1, weights='distance'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [i for i in df_gen.columns if i not in ['cls',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -----------Train data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.81      0.85      0.83      2016\n",
      "           3       0.77      0.62      0.69      2257\n",
      "           4       0.88      0.98      0.93      2386\n",
      "           5       0.86      0.88      0.87      2441\n",
      "\n",
      "    accuracy                           0.84      9100\n",
      "   macro avg       0.83      0.84      0.83      9100\n",
      "weighted avg       0.83      0.84      0.83      9100\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[1721  212    0   83]\n",
      " [ 384 1400  222  251]\n",
      " [   5   27 2349    5]\n",
      " [  12  183   87 2159]]\n",
      "\n",
      "       -----------Test data res------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.33      0.25      0.29         8\n",
      "           3       0.84      0.50      0.63        76\n",
      "           4       0.92      0.99      0.95       587\n",
      "           5       0.83      0.29      0.43        17\n",
      "\n",
      "    accuracy                           0.91       688\n",
      "   macro avg       0.73      0.51      0.58       688\n",
      "weighted avg       0.90      0.91      0.90       688\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[  2   2   4   0]\n",
      " [  4  38  34   0]\n",
      " [  0   5 581   1]\n",
      " [  0   0  12   5]]\n"
     ]
    }
   ],
   "source": [
    "get_results(clf_W2V,\n",
    "           df_gen[feature_cols],\n",
    "           df_gen['cls'],\n",
    "           test_x[feature_cols],\n",
    "           test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf_W2V.named_steps.data_W2V.index2word_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin_clf_W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_transformer = W2V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_w2V = W2V_transformer.transform(df_gen[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_w2V = W2V_transformer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dict = {}\n",
    "\n",
    "clf_dict[2] = RandomForestClassifier(max_depth=30, max_features='sqrt', min_samples_leaf=2,\n",
    "                                     min_samples_split=6, n_estimators=757)\n",
    "clf_dict[3] = SVC(C=990, class_weight='balanced', decision_function_shape='ovo', gamma=0.1,\n",
    "                  max_iter=10000)\n",
    "clf_dict[4] = KNeighborsClassifier(n_neighbors=20, weights='distance')\n",
    "clf_dict[5] = KNeighborsClassifier(n_neighbors=7, p=1, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_clf = Bin_clf(train_x_w2V.join(train_y), test_x_w2V, test_y, clf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    }
   ],
   "source": [
    "bin_clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    584\n",
       "3.0    101\n",
       "5.0      3\n",
       "Name: res, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_bin_w2v = bin_clf.predict()\n",
    "pred_y_bin_w2v.res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.12      0.16      0.14        76\n",
      "           4       0.86      0.85      0.85       587\n",
      "           5       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.74       688\n",
      "   macro avg       0.24      0.25      0.25       688\n",
      "weighted avg       0.74      0.74      0.74       688\n",
      "\n",
      "[[  0   0   0   0]\n",
      " [  3  12  84   2]\n",
      " [  5  64 500  15]\n",
      " [  0   0   3   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konstantin\\.conda\\envs\\ml_hse\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_y_bin_w2v))\n",
    "print(confusion_matrix(pred_y_bin_w2v, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
